{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras auto-compressor\n",
    "\n",
    "This notebook was designed as an example to test the `keras_autocompressor` \n",
    "python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic modules\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Allow memory grwoth in the docker container\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change current directory to load our custom module\n",
    "%cd /app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the hyper model for the auto compression task\n",
    "from auto_compressor.hypermodels import HyperCompressedMobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment settings\n",
    "tensorflow_dataset = 'horses_or_humans'\n",
    "batch_size = 16\n",
    "max_search_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset for training and testing\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    tensorflow_dataset, \n",
    "    split=['train', 'test'], \n",
    "    shuffle_files=True, \n",
    "    with_info=True, \n",
    "    as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pre-processing function for the images\n",
    "def preprocess_images(\n",
    "        image, \n",
    "        label, \n",
    "        num_classes=ds_info.features['label'].num_classes\n",
    "    ):\n",
    "    # Resize images\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224,224))\n",
    "\n",
    "    # Preprocess with the MobileNet function\n",
    "    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "\n",
    "    # Change labels to categorical\n",
    "    label = tf.cast(\n",
    "        tf.one_hot(tf.cast(label, tf.int32), num_classes), dtype=tf.float32\n",
    "    )\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the images\n",
    "ds_train = ds_train.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches for inference in both subsets\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)   \n",
    "\n",
    "ds_test = ds_test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our Hyper model\n",
    "hyper_model = HyperCompressedMobileNetV2(\n",
    "    max_parameters=2309581,\n",
    "    num_classes=ds_info.features['label'].num_classes,\n",
    "    tau=0.8,\n",
    ")\n",
    "\n",
    "# Create the tuner object for our search\n",
    "mobilenetv2_compressor = kt.Hyperband(\n",
    "    hyper_model,\n",
    "    max_epochs=max_search_epochs,\n",
    "    objective=kt.Objective(\"val_acc_comp\", direction=\"max\"),\n",
    "    directory='./logs/mobilenetv2/',\n",
    "    project_name=tensorflow_dataset,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hyperparameters search + auto compression\n",
    "mobilenetv2_compressor.search(ds_train, validation_data=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyper parameters after the search\n",
    "best_hyperparameters = mobilenetv2_compressor.get_best_hyperparameters()[0]\n",
    "for key, item in best_hyperparameters.values.items():\n",
    "    print(f'Hyperparameter: {key:20} | Value: {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = mobilenetv2_compressor.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the performance for the top-5 models obtained\n",
    "for idx, sub_model in enumerate(mobilenetv2_compressor.get_best_models(5), start=1):\n",
    "    metrics = sub_model.evaluate(ds_test, verbose=0)\n",
    "    print(f'Top-{idx} model | val_accuracy: {metrics[1]:0.4f}  | params:' \\\n",
    "          + f' {sub_model.count_params()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top-3 best models and their hyperparameters within the search\n",
    "mobilenetv2_compressor.results_summary(num_trials=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_V24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "a10ff3ee30b65286ff443e7a8165aacf8c3a251c5ca934082f0ceaa34dfa7297"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
